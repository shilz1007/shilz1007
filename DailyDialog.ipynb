{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1mOuS5TTMznMVxm7yJXrlVaJpgys4KCHT",
      "authorship_tag": "ABX9TyOKmpyW4aL4NMdJ48epF+41",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shilz1007/shilz1007/blob/main/DailyDialog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9CLV4rr7je1y"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import codecs\n",
        "import csv\n",
        "import os\n",
        "import unicodedata\n",
        "import re\n",
        "import itertools\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import unicodedata\n",
        "import re\n",
        "import argparse\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "#from transformers import GPT2Tokenizer,TFGPT2LMHeadModel \n",
        "from argparse import Namespace\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8TPhVLeCisQp"
      },
      "outputs": [],
      "source": [
        "path1 = '/content/drive/MyDrive/Daily-Dialog/dialogues_train.txt'\n",
        "path2 = '/content/drive/MyDrive/Daily-Dialog/dialogues_act_train.txt'\n",
        "path3 = '/content/drive/MyDrive/Daily-Dialog/dialogues_test.txt'\n",
        "path4 = '/content/drive/MyDrive/Daily-Dialog/dialogues_act_test.txt'\n",
        "path5 = '/content/drive/MyDrive/Daily-Dialog/dialogues_validation.txt'\n",
        "path6 = '/content/drive/MyDrive/Daily-Dialog/dialogues_act_validation.txt'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bk-yUaD00Id3"
      },
      "outputs": [],
      "source": [
        "#corpus_name = \"dailydialog\"\n",
        "#corpus = os.path.join(\"data\", corpus_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zQjLub5wzSWB"
      },
      "outputs": [],
      "source": [
        "def print_lines(file,n=10):\n",
        "  with open(file,'r',encoding='utf-8') as datafile:\n",
        "    lines = datafile.readlines()\n",
        "  for line in lines[:n]:\n",
        "    print(line)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "1oCPcYmbuGea"
      },
      "outputs": [],
      "source": [
        "def load_lines(input_file):\n",
        "  conversations = []\n",
        "  with open(input_file,'r',encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      values = line.split(\"__eou__\")\n",
        "      conversations.append(values)\n",
        "  return conversations   \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_dialog(acts):\n",
        "  dialog =[]\n",
        "  with open(acts,'r',encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      for word in line.split():\n",
        "        #for i in range(len(line) - 1):\n",
        "        dialog.append(word)\n",
        "        #  input_act = line[i]\n",
        "        #  target_act = line[i + 1]\n",
        "        #  print('input_act',input_act)\n",
        "        #  print('target_act',target_act)\n",
        "          #print(word)\n",
        "        #  #dialog.append([str(first),str(second)]) \n",
        "        #  dialog.append([input_act,target_act])\n",
        "  return dialog    "
      ],
      "metadata": {
        "id": "slsUz47vnmoe"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "QaXi7jiow73_"
      },
      "outputs": [],
      "source": [
        "def extract_sentence_pairs(conversations):\n",
        "  conv_pairs = []\n",
        "  for conversation in conversations:\n",
        "    for i in range(len(conversation) - 1):\n",
        "      input_line = conversation[i].strip()\n",
        "      target_line = conversation[i+1].strip()\n",
        "      if input_line and target_line:\n",
        "        conv_pairs.append([input_line,target_line])\n",
        "  return conv_pairs      "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(s):\n",
        "  return ''.join(c for c in unicodedata.normalize('NFD',s)\n",
        "                 if unicodedata.category(c) != 'Mn')"
      ],
      "metadata": {
        "id": "Hx46lkPk751F"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize_string(s):\n",
        "    s = unicode_to_ascii(s.lower().strip())\n",
        "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
        "    s = re.sub(r\"\\s+([.!?])\", r\"\\1\", s)\n",
        "    s = s.rstrip(\".,!?\")\n",
        "    return s"
      ],
      "metadata": {
        "id": "1QzuFhcyJPQx"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def normalize_string(s):\n",
        "#    s = s.lower().strip()\n",
        "#    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
        "#    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
        "#    s = re.sub(r\"\\s+\", r\" \", s).rstrip(\".,!?\")\n",
        "#    return s"
      ],
      "metadata": {
        "id": "MrZ3onk8MbIK"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_data(source,target,acts,type=None):\n",
        "  data_file = target\n",
        "  delimiter = '\\t'\n",
        "  delimiter = str(codecs.decode(delimiter,\"unicode_escape\"))\n",
        "\n",
        "  conversations = load_lines(source)\n",
        "  dialog_acts = load_dialog(acts)\n",
        "  #print(dialog_acts[0])\n",
        "  #print(conversations[0])\n",
        "  conv_pairs = []\n",
        "  for conversation in conversations:\n",
        "    for i in range(len(conversation) - 1):\n",
        "      input_line = conversation[i].strip()\n",
        "      target_line = conversation[i+1].strip()\n",
        "      if input_line and target_line:\n",
        "        conv_pairs.append([input_line,target_line])\n",
        "  print(conv_pairs[0]) \n",
        "  #merging dialog and dialog act     \n",
        "  conv_pairs_with_dialog_act = []\n",
        "  for i in range(len(conv_pairs)):\n",
        "    input_line = conv_pairs[i][0]\n",
        "    target_line = conv_pairs[i][1]\n",
        "    input_act = dialog_acts[i]\n",
        "    target_act = dialog_acts[i+1]\n",
        "\n",
        "    conv_pairs_with_dialog_act.append([input_line,target_line,input_act,target_act])\n",
        "\n",
        "  print(conv_pairs_with_dialog_act[0])  \n",
        "  #conv_pairs_normalize = []\n",
        "  #for i in range(len(conv_pairs_with_dialog_act)):\n",
        "  #   input_line = normalize_string(conv_pairs_with_dialog_act[i][0])\n",
        "  #   target_line = normalize_string(conv_pairs_with_dialog_act[i][1])\n",
        "  #   input_act = normalize_string(conv_pairs_with_dialog_act[i])\n",
        "  #   target_act = normalize_string(conv_pairs_with_dialog_act[i+1])\n",
        "  #   conv_pairs_normalize.append([input_line,target_line,input_act,target_act])\n",
        "  #print(conv_pairs_normalize[0])\n",
        "  #Writing out the combined dataset \n",
        "  print('\\n writing a new file')\n",
        "  with open(data_file,'w',encoding='utf-8') as output_file:\n",
        "    writer = csv.writer(output_file,delimiter=delimiter,lineterminator='\\n')\n",
        "    for pair in conv_pairs_with_dialog_act:\n",
        "      writer.writerow(pair)\n",
        "\n",
        "\n",
        "\n",
        "  \n",
        "\n",
        "  \n",
        "  \n",
        "  \n"
      ],
      "metadata": {
        "id": "uZyZ--wAfJGc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "format_data(source=path1,target =\"/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_train.txt\" ,acts=path2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIMNfrO8gMg2",
        "outputId": "21e27f81-69de-42d3-9f88-25c57aef2e29"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Say , Jim , how about going for a few beers after dinner ?', 'You know that is tempting but is really not good for our fitness .']\n",
            "['Say , Jim , how about going for a few beers after dinner ?', 'You know that is tempting but is really not good for our fitness .', '3', '4']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_data(source=path5,target =\"/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_valid.txt\",acts=path6)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N40xkFlJ6gOX",
        "outputId": "e0cde744-4517-4ae4-e2e9-3e21d850c522"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good morning , sir . Is there a bank near here ?', 'There is one . 5 blocks away from here ?']\n",
            "['Good morning , sir . Is there a bank near here ?', 'There is one . 5 blocks away from here ?', '2', '1']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "format_data(source=path3,target =\"/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_test.txt\",acts=path4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mBHpFURQyPta",
        "outputId": "7fa79d7e-b369-4fcb-ea6c-179b2b34f197"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hey man , you wanna buy some weed ?', 'Some what ?']\n",
            "['Hey man , you wanna buy some weed ?', 'Some what ?', '3', '2']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6W1dpOtT2Vp8"
      },
      "outputs": [],
      "source": [
        "#reading the formatted file\n",
        "train_file = '/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_train.txt'\n",
        "valid_file = '/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_valid.txt'\n",
        "test_file = '/content/drive/MyDrive/Daily-Dialog/formatted_dialogues_test.txt'\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_input_file(input_file):\n",
        "  n = 10\n",
        "  with open(input_file,'r',encoding='utf-8') as datafile:\n",
        "     lines = datafile.readlines()\n",
        "     for line in lines[:n]:\n",
        "       print(line)"
      ],
      "metadata": {
        "id": "NdRyGfoo2FY5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_file = read_input_file(train_file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uO-yPwTD3ALA",
        "outputId": "7f66a596-7ff8-44a4-9950-1b32094b6107"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Say , Jim , how about going for a few beers after dinner ?\tYou know that is tempting but is really not good for our fitness .\t3\t4\n",
            "\n",
            "You know that is tempting but is really not good for our fitness .\tWhat do you mean ? It will help us to relax .\t4\t2\n",
            "\n",
            "What do you mean ? It will help us to relax .\tDo you really think so ? I don't . It will just make us fat and act silly . Remember last time ?\t2\t2\n",
            "\n",
            "Do you really think so ? I don't . It will just make us fat and act silly . Remember last time ?\tI guess you are right.But what shall we do ? I don't feel like sitting at home .\t2\t2\n",
            "\n",
            "I guess you are right.But what shall we do ? I don't feel like sitting at home .\tI suggest a walk over to the gym where we can play singsong and meet some of our friends .\t2\t3\n",
            "\n",
            "I suggest a walk over to the gym where we can play singsong and meet some of our friends .\tThat's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .\t3\t4\n",
            "\n",
            "That's a good idea . I hear Mary and Sally often go there to play pingpong.Perhaps we can make a foursome with them .\tSounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .\t4\t1\n",
            "\n",
            "Sounds great to me ! If they are willing , we could ask them to go dancing with us.That is excellent exercise and fun , too .\tGood.Let ' s go now .\t1\t3\n",
            "\n",
            "Good.Let ' s go now .\tAll right .\t3\t4\n",
            "\n",
            "Can you do push-ups ?\tOf course I can . It's a piece of cake ! Believe it or not , I can do 30 push-ups a minute .\t4\t2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preprocess data \n",
        "def preprocess_data(infile,target):\n",
        "\n",
        "  # add generic responses\n",
        "  # change all the words to lower character.\n",
        "  # remove stop words and special character\n",
        "  # format for unicode to ascii \n",
        "  delimiter = '\\t'\n",
        "  output = target\n",
        "\n",
        "  #if args.infile == train_file:\n",
        "  #   output = os.path.join(args.data_path, \"train.txt\")\n",
        "  #else:   \n",
        "  #   output = os.path.join(args.data_path, \"valid.txt\") \n",
        "  \n",
        "  \n",
        "  #path = '/content/drive/MyDrive/Daily-Dialog'\n",
        "  new_pair = []\n",
        "\n",
        "  with open(infile,'r',encoding='utf-8') as f:\n",
        "    for line in f:\n",
        "      try:\n",
        "        input_line,target_line,dialog_act_input,dialog_act_target = line.strip().split('\\t')\n",
        "      except ValueError:\n",
        "        print('skipping invalid line ',line)  \n",
        "      new_pair.append([input_line.strip(),target_line.strip(),dialog_act_input.strip(),dialog_act_target.strip()])\n",
        "\n",
        "  generic_responses = [\n",
        "    \"I see.\", \n",
        "    \"That's interesting.\", \n",
        "    \"Can you tell me more about that?\", \n",
        "    \"I'm not sure I understand. Can you clarify?\", \n",
        "    \"Thank you for sharing.\", \n",
        "    \"That's a good point.\", \n",
        "    \"I agree.\", \n",
        "    \"I disagree.\", \n",
        "    \"Let's change the topic.\", \n",
        "    \"That reminds me of something else.\",\n",
        "    \"I'm sorry, I don't have an answer for that.\",\n",
        "    \"I don't know what to say.\",\n",
        "    ]\n",
        "\n",
        "  p_generic_responses = 0.1\n",
        "\n",
        "  new_conv_pair = []\n",
        "\n",
        "  for input_line,target_line,dialog_act_input,dialog_act_target in new_pair:\n",
        "\n",
        "    new_conv_pair.append([input_line,target_line,dialog_act_input,dialog_act_target])\n",
        "    if random.random() < p_generic_responses:\n",
        "      generic_response = random.choice(generic_responses)\n",
        "      new_conv_pair.append([input_line,generic_response,dialog_act_input,'5'])\n",
        "\n",
        "  print(new_conv_pair[0]) \n",
        "  #normalize data\n",
        "  normalized_conv_pair = []\n",
        "\n",
        "  for pair in new_conv_pair:\n",
        "    input_line,target_line,dialog_act_input,dialog_act_target = pair\n",
        "\n",
        "    #normalize the input line and target line\n",
        "    input_line = normalize_string(input_line)\n",
        "    target_line = normalize_string(target_line)\n",
        "\n",
        "    #append the normalized pair back to the list\n",
        "\n",
        "    normalized_pair = [input_line,target_line,dialog_act_input,dialog_act_target]\n",
        "    normalized_conv_pair.append(normalized_pair)\n",
        "  print(normalized_conv_pair[0]) \n",
        "\n",
        "  \n",
        "\n",
        "  #for pair in normalized_conv_pair:\n",
        "  #  input_line,target_line,dialog_act_input,dialog_act_target = pair\n",
        "  #  if dialog_act_target == '5':\n",
        "  #    print(pair)\n",
        "  \n",
        "  #write output file \n",
        "  print('\\n writing a new file')\n",
        "  with open(output,'w',encoding='utf-8') as output_file:\n",
        "    writer = csv.writer(output_file,delimiter=delimiter,lineterminator='\\n')\n",
        "    for pair in normalized_conv_pair:\n",
        "      writer.writerow(pair)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "qeMghtR47oLT"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target = '/content/drive/MyDrive/Daily-Dialog/train.txt'"
      ],
      "metadata": {
        "id": "WbbRfYLc3nDR"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infile = preprocess_data(train_file,target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPMkGdQMAwVY",
        "outputId": "978b18e3-d650-4106-d3a0-23053820b7a1"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Say , Jim , how about going for a few beers after dinner ?', 'You know that is tempting but is really not good for our fitness .', '3', '4']\n",
            "['say jim how about going for a few beers after dinner', 'you know that is tempting but is really not good for our fitness', '3', '4']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = '/content/drive/MyDrive/Daily-Dialog/valid.txt'"
      ],
      "metadata": {
        "id": "EsrBlW4B32sR"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validfile = preprocess_data(valid_file,target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-772GaMqRUxZ",
        "outputId": "440f4b29-6388-41ec-f453-ca333fe7344e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Good morning , sir . Is there a bank near here ?', 'There is one . 5 blocks away from here ?', '2', '1']\n",
            "['good morning sir. is there a bank near here', 'there is one. blocks away from here', '2', '1']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target = '/content/drive/MyDrive/Daily-Dialog/test.txt'\n",
        "testfile = preprocess_data(test_file,target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyeS_im9yv0k",
        "outputId": "40c24a7a-02f6-4dd9-a0d2-b71f7964f849"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Hey man , you wanna buy some weed ?', 'Some what ?', '3', '2']\n",
            "['hey man you wanna buy some weed', 'some what', '3', '2']\n",
            "\n",
            " writing a new file\n"
          ]
        }
      ]
    }
  ]
}